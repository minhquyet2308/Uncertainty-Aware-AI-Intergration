import pandas as pd 
import numpy as np
import math
from sklearn.utils.multiclass import unique_labels
try:
    from scipy.misc import comb
except:
    from scipy.special import comb
import itertools
from collections import Counter
from copy import deepcopy
from sklearn.metrics import accuracy_score
from sklearn.base import BaseEstimator, ClassifierMixin

from sklearn.model_selection import (GridSearchCV, KFold, LeaveOneOut,
                                     RepeatedKFold, cross_val_predict,
                                     cross_validate, ParameterGrid)


class MassFunction(dict):
    """
    A Dempster-Shafer mass function (basic probability assignment) based on a dictionary.
    Hypotheses and their associated mass values can be added/changed/removed using the standard dictionary methods.
    Each hypothesis can be an arbitrary sequence which is automatically converted to a 'frozenset', meaning its elements must be hashable.
    """

    def __init__(self, source=None, coreset=None, cold_start="unknow", r=40):
        """
        Creates a new mass function.

        It be a dictionary mapping hypotheses to non-negative mass values
        If 'source' is not None, it is used to initialize the mass function depend on the option of cold start.
        If choosing 'unknow', the remain of mass value be assigned for the core set. 
        Otherwise, the mass values of non-focal set were assigned the mean of the remaining of mass value.
        """
        total_mass = 0
        self.coreset = coreset
        self.r = r
        if source != None:
            for (h, v) in source:
                self[frozenset(h)] = np.float64(v)
                total_mass += np.float64(v)

            if self.coreset == None:
                self.coreset = self.core()

        if self.coreset != None:
            if cold_start == "equal":
                initial_mass_value = np.float64((1.0 - total_mass) / (np.power(2, len(self.coreset)) - 1 - len(self)))
                for i in range(len(self.coreset)):
                    for hypothesis_set in itertools.combinations(self.coreset,i+1):
                        if frozenset(hypothesis_set) not in self:
                            self[frozenset(hypothesis_set)] = initial_mass_value
            elif cold_start == "unknow":
                for i in range(len(self.coreset)):
                    for hypothesis_set in itertools.combinations(self.coreset,i+1):
                        if frozenset(hypothesis_set) not in self:
                            self[frozenset(hypothesis_set)] = np.float64(0)
                self[frozenset(self.coreset)] = np.float64(1.0 - total_mass + self[frozenset(self.coreset)])
        # self.__round__()

    def focal(self): 
        """
        Returns the set of all focal hypotheses.

        A focal hypothesis has a mass value greater than 0.
        """
        return {h for (h, v) in self.items() if v > 0}

    def core(self):
        """
        Returns the core of a mass functions as a 'frozenset'.

        The core of a mass function is the union of all its focal hypotheses.
        In case a mass function does not contain any focal hypotheses, its core is an empty set.
        """
        focal = self.focal()
        if not focal:
            return frozenset()
        else:
            return frozenset.union(*focal)

    def combine(self, mass_function):
        """
        Returns a mass function was generated by combining these two mass funciton (self and mass function)

        The function use combination rules in theory of evidence for itegrating evidence.
        """
        if self.coreset != mass_function.coreset:
            raise TypeError("expected core set of the MassFunctions are the same but got two difference core set: {} and {}".format(self.coreset, mass_function.coreset))
        combined = self
        if isinstance(mass_function, MassFunction):
            mass_function = [mass_function] # wrap single mass function
        for m in mass_function:
            if not isinstance(m, MassFunction):
                raise TypeError("expected type MassFunction but got %s; make sure to use keyword arguments for anything other than mass functions" % type(m))
            combined = combined.__combine_dempster_rule__(m)
        # combined.__round__()
        return combined
    
    def __combine_dempster_rule__(self, mass_function):
        """
        Returns a mass function was combined using Dempster's Rule

        The function use Dempster's Rule  for combining evidence.
        """
        # print("Test")
        combined = MassFunction(coreset=self.coreset)
        # print(combined)
        for (h, v) in self.items():
            combined[h] = 0
        total_mass = 0.0
        for (h1, v1) in self.items():
            for (h2, v2) in mass_function.items():
                if len(frozenset.intersection(h1, h2)) != 0:
                    combined[frozenset.intersection(h1, h2)] += (v1 * v2)
                    total_mass += (v1 * v2)

        # print(combined, total_mass)
        for (h, v) in combined.items():
            combined[h] = combined[h] / total_mass
        return combined

    def __solve_totally_conflict__(self):
        """
        Solving the total conflict between mass functions by adding an epsilon to the Omega set.
        """
        if self[frozenset(self.coreset)] == 0.0:
            max_hypothesis = None
            max_value = 0.0
            for (h, v) in self.items():
                if v > max_value:
                    max_value = v
                    max_hypothesis = h

            self[frozenset(self.coreset)] = 1e-32
            self[max_hypothesis] = self[max_hypothesis] - 1e-32

    def __round__(self):
        """
        Returns a rouned mass function

        The function use round function for aproximating the mass values in the mass function.
        The parameter 'r' defined the number of decimal for rounding the final mass function.
        """

        total_mass = 0
        # print("----------Round-----------")
        # print(self)
        for i in range(len(self.coreset) - 1):
            for hypothesis_set in itertools.combinations(self.coreset,i + 1):
                self[frozenset(hypothesis_set)] = round(self[frozenset(hypothesis_set)], self.r)
                total_mass = total_mass + self[frozenset(hypothesis_set)]
        # print(total_mass)
        self[frozenset(self.coreset)] = 1.0 - total_mass
        self.__solve_totally_conflict__()
        # print(self)
        # print("---------------------")
        
    def pignistic(self):
        betp = []
        for coreset in self.coreset:
            tmp_betp = 0
            for (h, v) in self.items():
                if coreset in h:
                    tmp_betp += v/len(h)
            betp.append(tmp_betp) 
        return betp
                        
class SimilarityCombinationElement(object):
    """
    A module, which is based on Dempster-Shafer theory, measures similarity between (1) elements, (2) element and combination of element, and (3) combinations of element.
    The module uses mass functions to model pieces of evidence about the similarity, which are collected from the data set.
    It should be noted that the instance in work is a multi-principal-element alloy (list of element).
    This module provides two running modes: single or parallel (using Spark).
    """

    def __init__(self, data, rage_size_subset=1, seperate_symbol="|", alpha=0.1, core_set=None, version="v1", discounting_factor=1):
        """
        Creates a new object to measure the similarity.

        data: set of counters (name of item and number of the item) representing data instances.
        rage_size_subset: max length of the combinations of element which are considered about their similarity.
        seperate_symbol: symbol is used to separate elements in the instances of the data set.
        alpha (or alpha): a hyperparameter is used to handle the conflict between pieces of evidence.
        """
        self.data = data
        self.seperate_symbol = seperate_symbol
        self.rage_size_subset = rage_size_subset
        self.alpha = alpha
        self.version = version
        self.core_set = core_set
        self.subsets = self.__generate_subsets__()
        self.discounting_factor = discounting_factor

    def __generate_subsets__(self):
        """
        Return list of subsets (elements or combinations of elements) is considered about their similarity with each other.
        """
        subsets = []
        for size_subset in range(self.rage_size_subset + 1):
            for subset in itertools.combinations_with_replacement(self.core_set, size_subset):
                subsets.append(subset)
        return subsets
    
    def __generate_similarity_matrices__(self):
        """
        Return data frames containing data frames contain similarity, dissimilarity and uncertainty between considered subsets.
        """
        n_subsets = len(self.subsets)
        columns_name = [self.seperate_symbol.join(sorted(k)) for k in self.subsets]

        similarity_matrix = np.zeros((n_subsets,n_subsets))
        np.fill_diagonal(similarity_matrix, 1)
        df_similarity = pd.DataFrame(similarity_matrix, columns=columns_name, index=columns_name)

        dissimilarity_matrix = np.zeros((n_subsets,n_subsets))
        df_dissimilarity = pd.DataFrame(dissimilarity_matrix, columns=columns_name, index=columns_name)

        unknown_matrix = np.ones((n_subsets,n_subsets))
        np.fill_diagonal(unknown_matrix, 0)
        df_uncertainty = pd.DataFrame(unknown_matrix, columns=columns_name, index=columns_name)

        self.df_similarity = df_similarity
        self.df_dissimilarity = df_dissimilarity
        self.df_uncertainty = df_uncertainty

    def get_pairwise_subsets(self):
        """
        Return list of pairwise considered subsets.
        """
        pairwise_subsets = itertools.combinations(self.subsets, 2)
        return pairwise_subsets

    def __extract_evidence__(self, elements_i, elements_j):
        intersection_ai_aj = list((elements_i & elements_j).elements())
        combination_t = list((elements_i - elements_j).elements())
        combination_v = list((elements_j - elements_i).elements())
        n_i = len(list((elements_i).elements()))
        n_j = len(list((elements_j).elements()))

        # Extract evidence from Ai and Aj that their intersection is not empty
        if len(intersection_ai_aj) == 0 or len(combination_t) > self.rage_size_subset or len(combination_v) > self.rage_size_subset or (len(combination_t)==0 and len(combination_v)==0):
            return None
        else:
            union_ai_aj = list((elements_i | elements_j).elements())
            j_index = (np.sqrt(np.power(len(intersection_ai_aj),2)/(len(union_ai_aj)*np.min([n_i,n_j])))+1)/(2*np.max([len(combination_t), len(combination_v)]))
            return intersection_ai_aj, combination_t, combination_v, j_index
    
    def __collect_source_of_evidence__(self, mask_matrix=None):
        if mask_matrix is not None:
            for i, j in np.argwhere(mask_matrix==1):
                yield (self.data[i], self.data[j])
        else:
            for i, j in itertools.combinations(self.data, 2):
                yield (i, j)
    
    def __model_evidence__(self, source_of_evidence):
        """
        Return list of similarity between considered subsets.
        """
        alloy_i, alloy_j = source_of_evidence[0], source_of_evidence[1]
        if np.abs(alloy_i[2]-alloy_j[2])<=2:
            evidence = self.__extract_evidence__(alloy_i[0], alloy_j[0])
            if evidence is not None:
                alpha = alloy_i[3] * alloy_j[3] * self.alpha
                intersection_ai_aj, combination_t, combination_v, j_index = evidence
                # Evaluate the discounting factor for the source of evidence
                if self.version in ["v1", "v2"]:
                    j_index = 1
                if alloy_i[1] == alloy_j[1]:
                    mass_function = MassFunction(source=[({"similar"}, np.float64(alpha*j_index))], coreset={"similar", "dissimilar"})
                else:
                    mass_function = MassFunction(source=[({"dissimilar"}, np.float64(alpha*j_index))], coreset={"similar", "dissimilar"})
                index_t, index_v = "|".join(sorted(combination_t)), "|".join(sorted(combination_v))
                return (tuple(sorted([index_t, index_v])), mass_function)
            else:
                return None
        else:
            return None

    def __combine_evidence_with_spark__(self, key_values):
        similar_set = frozenset({"similar"})
        dissimilar_set = frozenset({"dissimilar"})
        unknown_set = frozenset({"similar", "dissimilar"})
        
        index_t, index_v, mass_functions = key_values[0][0], key_values[0][1], key_values[1]
        combined_mass_function = MassFunction(
            source=[
                ({"similar"}, np.float64(0)), 
                ({"dissimilar"}, np.float64(0)), 
                ({"similar", "dissimilar"}, np.float64(1))
            ], coreset={"similar", "dissimilar"}
        )
        for mass_function in mass_functions:
            combined_mass_function = mass_function.combine(combined_mass_function)
        return ((index_t, index_v), (combined_mass_function[similar_set], combined_mass_function[dissimilar_set], combined_mass_function[unknown_set]))
        
    def __combine_evidence__(self, mass_functions):
        similar_set = frozenset({"similar"})
        dissimilar_set = frozenset({"dissimilar"})
        unknown_set = frozenset({"similar", "dissimilar"})
        
        for ((index_t, index_v), mass_function) in mass_functions:
            # index_t, index_v = "|".join(sorted(combination_t)), "|".join(sorted(combination_v))
            similar_score = self.df_similarity.loc[index_t, index_v]
            dissimilar_score = self.df_dissimilarity.loc[index_t, index_v]
            unk_score = self.df_uncertainty.loc[index_t, index_v]
            combined_mass_function = mass_function.combine(
                MassFunction(
                    source=[
                        ({"similar"}, np.float64(similar_score)), 
                        ({"dissimilar"}, np.float64(dissimilar_score)), 
                        ({"similar", "dissimilar"}, np.float64(unk_score))
                    ], coreset={"similar", "dissimilar"}
                )
            )
            
            # Update matrices
            self.__update_similarity_matrices__(
                index_t=index_t, index_v=index_v, similar_score=combined_mass_function[similar_set],
                dissimilar_score=combined_mass_function[dissimilar_set], unk_score=combined_mass_function[unknown_set]
            )
            
    def __update_similarity_matrices__(
        self, index_t, index_v, 
        similar_score, dissimilar_score, unk_score
    ):
        self.df_similarity.loc[index_t, index_v] = similar_score*self.discounting_factor
        self.df_dissimilarity.loc[index_t, index_v] = dissimilar_score*self.discounting_factor
        self.df_uncertainty.loc[index_t, index_v] = 1-self.discounting_factor + unk_score*self.discounting_factor
        self.df_similarity.loc[index_v, index_t] = similar_score*self.discounting_factor
        self.df_dissimilarity.loc[index_v, index_t] = dissimilar_score*self.discounting_factor
        self.df_uncertainty.loc[index_v, index_t] = 1-self.discounting_factor + unk_score*self.discounting_factor
            
    def similarity_measurement(self, spark=False, mask_matrix=None):
        """
        Return list of similarity between considered subsets.
        """
        sources_of_evidence = self.__collect_source_of_evidence__(mask_matrix)
        
        # Collect and model evidence
        if spark:
            from pyspark import SparkConf, SparkContext
            conf = (SparkConf().set("spark.driver.maxResultSize", "16g"))
            sc = SparkContext(
                appName="Model substitution method",
                conf=conf
            )
            broadcast_self = sc.broadcast(self)
            rdd = sc.parallelize(sources_of_evidence, numSlices=1024)
            
            # Model evidence
            rdd_similarity_measurement = rdd.map(
                lambda evidence: broadcast_self.value.__model_evidence__(evidence)
            ).filter(lambda x: x is not None).groupByKey().map(
                lambda key_values: broadcast_self.value.__combine_evidence_with_spark__(key_values)
            )
            results = rdd_similarity_measurement.collect()
            
            # Parse the rdd to similarity matrices
            self.__generate_similarity_matrices__()
            for (index_t, index_v), (similar_score, dissimilar_score, unk_score) in results:
                self.__update_similarity_matrices__(
                    index_t=index_t, index_v=index_v, similar_score=similar_score,
                    dissimilar_score=dissimilar_score, unk_score=unk_score
                )

            # Unpersist RDDs to clear memory
            rdd.unpersist(blocking=True)
            rdd_similarity_measurement.unpersist(blocking=True)

            # remove broadcast variables
            broadcast_self.destroy(blocking=True)

            # Stop the spark context
            sc.stop()
        else:
            # Model evidence
            mass_functions = []
            for evidence in sources_of_evidence:
                mass_function = self.__model_evidence__(evidence)
                if mass_function is not None:
                    mass_functions.append(mass_function)

            # Generate similarity matrices and combine evidence
            self.__generate_similarity_matrices__()
            self.__combine_evidence__(mass_functions)
        
    def to_csv(self, output_dir, prefix=None):
        """
        Save calculated data frames to files.

        output_dir: a path of the destination folder to save the data frames.
        """
        if prefix is None:
            self.df_similarity.to_csv("{}/similarity.csv".format(output_dir))
            self.df_dissimilarity.to_csv("{}/dissimilarity.csv".format(output_dir))
            self.df_uncertainty.to_csv("{}/uncertainty.csv".format(output_dir))
        else:
            self.df_similarity.to_csv("{}/{}_similarity.csv".format(output_dir, prefix))
            self.df_dissimilarity.to_csv("{}/{}_dissimilarity.csv".format(output_dir, prefix))
            self.df_uncertainty.to_csv("{}/{}_uncertainty.csv".format(output_dir, prefix))
    
    def to_parquet(self, output_dir, prefix=None):
        """
        Save calculated data frames to parquet files.

        output_dir: a path of the destination folder to save the data frames.
        """
        if prefix is None:
            self.df_similarity.to_parquet("{}/similarity.parquet".format(output_dir))
            self.df_dissimilarity.to_parquet("{}/dissimilarity.parquet".format(output_dir))
            self.df_uncertainty.to_parquet("{}/uncertainty.parquet".format(output_dir))
        else:
            self.df_similarity.to_parquet("{}/{}_similarity.parquet".format(output_dir, prefix))
            self.df_dissimilarity.to_parquet("{}/{}_dissimilarity.parquet".format(output_dir, prefix))
            self.df_uncertainty.to_parquet("{}/{}_uncertainty.parquet".format(output_dir, prefix))

class CombinationDistance(object):
    
    def __init__(self, data):
        self.data = data
        
    def distance(self, i, j, w=None):
        combination_t = len(list((data[int(i[0])][0] - data[int(j[0])][0]).elements()))
        combination_v = len(list((data[int(j[0])][0] - data[int(i[0])][0]).elements()))
        return np.max([combination_t, combination_v])

class EvidentialClassifier(BaseEstimator, ClassifierMixin):
    """
    An evidence-based classification module using Dempster-Shafer theory.
    The module uses mass function to model pieces of evidence about the property of the new instance, which are collected from the data set.
    It should be noted that the instance in the work is a multi-principal-element alloy (list of element).
    This module provides two running modes: single or parallel (using Spark).
    """

    def __init__(self, core_set, frame_of_discernment, seperate_symbol="|", n_gram_evidence=2, alpha=0.1, version="v1", df_mask_matrix=None, discounting_factor=1):
        """
        Creates a new classifier.

        It is an object to classify new instance based on the observed data set.
        seperate_symbol: symbol is used to separate elements in the instances of the data set.
        n_gram_evidence: max length of the combinations of element which are used to generate the new instance from observed instances based on substitution method.
        alpha (or alpha): a hyperparameter is used to handle the conflict between pieces of evidence.
        """
        self.seperate_symbol = seperate_symbol
        self.n_gram_evidence = n_gram_evidence
        self.alpha = alpha
        self.core_set = core_set
        self.version = version
        self.frame_of_discernment = frozenset(frame_of_discernment)
        self.df_mask_matrix = df_mask_matrix
        self.discounting_factor = discounting_factor

    def __extract_mask_matrix__(self, idx1, idx2):
        mask_matrix = None
        if self.df_mask_matrix is not None:
            mask_matrix = self.df_mask_matrix.loc[idx1, idx2].values
        return mask_matrix

    def __base_fit__(self, X, y, spark=False, weights=None):
        self.idx_obs = X
        self.classes_ = np.array(["Low", "High"])
        # self.classes_ = unique_labels(y)
        
        # Parse the data into the form of Counter objects
        self.data = []
        if weights is None:
            weights = np.ones(len(X))
        for set_name, label, w in zip(X, y, weights):
            set_name = set_name.split(self.seperate_symbol)
            self.data.append(tuple([Counter(set_name), label, len(set_name), w]))

        mask_matrix = self.__extract_mask_matrix__(self.idx_obs, self.idx_obs)
        if mask_matrix is not None:
            iu = np.triu_indices(len(mask_matrix))
            mask_matrix[iu] = 0

        # Init similarity informatioon
        similarity_information = SimilarityCombinationElement(
            data=self.data, rage_size_subset=self.n_gram_evidence, seperate_symbol=self.seperate_symbol, 
            alpha=self.alpha, core_set=self.core_set, version=self.version, discounting_factor=self.discounting_factor
        )
        return similarity_information, mask_matrix
    
    def fit(self, X, y, spark=False, weights=None):
        # Init base objects
        similarity_information, mask_matrix = self.__base_fit__(X, y, spark, weights)
            
        # Measure similarity between materials
        similarity_information.similarity_measurement(spark, mask_matrix)
        self.similarity_information = similarity_information

    def score(self, X, y, spark=False):
        y_pred, final_decisions = self.predict(X, show_decision=True, spark=spark)
        m_High, m_Low, m_Unk = [], [], []
        for final_decision in final_decisions:
            m_High.append(final_decision[frozenset({"High"})])
            m_Low.append(final_decision[frozenset({"Low"})])
            m_Unk.append(final_decision[frozenset({"High", "Low"})])
        m_Unk = np.array(m_Unk)
        y, y_pred = np.array(y), np.array(y_pred)
        return accuracy_score(y[m_Unk!=1], y_pred[m_Unk!=1])
        
    def __extract_evidence__(self, alloy_new, alloy_k):
        c_intersection = list((alloy_k & alloy_new).elements())
        n_new = len(list((alloy_new).elements()))
        n_k = len(list((alloy_k).elements()))
        if len(c_intersection)!= 0 and alloy_k != alloy_new:
            combination_t = list((alloy_k - alloy_new).elements())
            combination_v = list((alloy_new - alloy_k).elements())
            if len(combination_t) <= self.n_gram_evidence and len(combination_v) <= self.n_gram_evidence: 
                index_t, index_v = "|".join(sorted(combination_t)), "|".join(sorted(combination_v))
                similar_score = self.similarity_information.df_similarity.loc[index_t, index_v]
                dissimilar_score = self.similarity_information.df_dissimilarity.loc[index_t, index_v]
                unknown_score = self.similarity_information.df_uncertainty.loc[index_t, index_v]
                if unknown_score != 1:
                    c_union = list((alloy_k | alloy_new).elements())
                    j_index =(np.sqrt(np.power(len(c_intersection),2)/(len(c_union)*np.min([n_new,n_k])))+1)/(2*np.max([len(combination_t), len(combination_v)]))
                    return combination_t, combination_v, similar_score, dissimilar_score, unknown_score, j_index
                else:
                    return None
            else:
                return None
        return None

    def __sampling_decision__(self, final_decision, baseline_prediction=None):
        if baseline_prediction is None:
            pignistic = final_decision.pignistic()
            y_pred = np.array(list(final_decision.coreset))[np.argmax(pignistic)]
            return y_pred
        else:
            # Sampling prediction from mass function
            sample = []
            m_High, m_Low, m_Unk = final_decision[frozenset({"High"})], final_decision[frozenset({"Low"})], final_decision[frozenset({"High", "Low"})]
            for i in np.random.uniform(0, 1, 999):
                if i <= m_High:
                    sample.append("High")
                elif i <= (m_High + m_Low):
                    sample.append("Low")
                else:
                    sample.append(np.random.choice(["High", "Low"], 1, p=baseline_prediction)[0])
            sample = np.array(sample)
            n_H, n_L = np.sum(sample=="High"), np.sum(sample=="Low")
            y_pred = "High" if n_H > n_L else "Low"
            return y_pred
        
    def __modelling_belief__(self, material, baseline_prediction=None):
        mask = np.ones(len(self.data))
        # Init the variables
        pieces_of_evidence = []
        material = material.split(self.seperate_symbol)
        candidate = Counter(material)
        final_decision = MassFunction(coreset=self.frame_of_discernment)
        for i in np.argwhere(mask==1).flatten():
            alloy_k, label_k, len_k, w_k = self.data[i]
            if np.abs(len(material)-len_k) <= 2:
                evidence = self.__extract_evidence__(candidate, alloy_k)
                if evidence is not None:
                    combination_t, combination_v, similar_score, dissimilar_score, unknown_score, j_index = evidence
                    # Model the evidence
                    if self.version == "v1":
                        mass_function = MassFunction(source=[({label_k}, np.float64(similar_score))], coreset=self.frame_of_discernment)
                        # mass_function = MassFunction(source=[({label_k}, np.float64(similar_score*self.alpha))], coreset=self.frame_of_discernment)
                    elif self.version =="v2":
                        mass_function = MassFunction(
                            source=[
                                ({label_k}, np.float64(similar_score*self.alpha)),
                                (self.frame_of_discernment.difference(frozenset({label_k})), np.float64(dissimilar_score*self.alpha))
                            ], 
                            coreset=self.frame_of_discernment
                        )
                    elif self.version =="v3":
                        # Evaluate the discounting factor for the source of evidence
                        mass_function = MassFunction(
                            source=[
                                ({label_k}, np.float64(j_index*similar_score*self.alpha)),
                                (self.frame_of_discernment.difference(frozenset({label_k})), np.float64(j_index*dissimilar_score*self.alpha))
                            ], 
                            coreset=self.frame_of_discernment
                        )
                    elif self.version == "v5":
                        discounting_factor = j_index * w_k * self.alpha
                        mass_function = MassFunction(
                            source=[
                                ({label_k}, np.float64(discounting_factor*similar_score)),
                                (self.frame_of_discernment.difference(frozenset({label_k})), np.float64(discounting_factor*dissimilar_score))
                            ], 
                            coreset=self.frame_of_discernment
                        )
                    # Combine the evidence
                    final_decision = final_decision.combine(mass_function)
                    # Save the modeled evidence
                    pieces_of_evidence.append([alloy_k, combination_t, combination_v, mass_function])

        # Sampling prediction from mass function
        y_pred = self.__sampling_decision__(final_decision, baseline_prediction)
        
        # return pieces_of_evidence, final_decision
        return y_pred, final_decision
    
    def save_similarity_matrices(self, output_dir):
        """
        Save similarity information to data frames.

        output_dir: a path of the destination folder to save the data frames.
        """
        self.similarity_information.to_parquet(output_dir)
        
    def __predict__(self, X, trace=False, spark=False, show_decision=False, baseline_predictions=None):
        """
        Returns the predicted labels of new instances (materials).

        trace: If True, the function adds lists of pieces of evidence, which are used to estimate properties of the new instances, to the output.
        show_decision: If True, the function adds the combined mass function of collected pieces of evidence to the output.
        spark: If True, the function is deployed on the Spark system to accelerate runtime.
        """
        y_pred = []
        final_decisions = []
        if baseline_predictions is None:
            baseline_predictions = [None] * len(X) 
        
        # Collect and model evidence
        if spark:
            from pyspark import SparkConf, SparkContext
            conf = (SparkConf().set("spark.driver.maxResultSize", "16g"))
            sc = SparkContext(
                appName="Estimate substitution results",
                conf=conf
            )
            broadcast_self = sc.broadcast(self)
            rdd = sc.parallelize(zip(X, baseline_predictions), numSlices=1024)
            
            # Model evidence
            rdd_estimation = rdd.map(
                lambda item: broadcast_self.value.__modelling_belief__(item[0], item[1])
            )
            results = rdd_estimation.collect()
            
            for (y_sample, final_decision) in results:
                y_pred.append(y_sample)
                final_decisions.append(final_decision)

            # Unpersist RDDs to clear memory
            rdd.unpersist(blocking=True)
            rdd_estimation.unpersist(blocking=True)
            
            # remove broadcast variables
            broadcast_self.destroy(blocking=True)

            # Stop the spark context
            sc.stop()
        else:
            for i, material in enumerate(X):
                y_sample, final_decision = self.__modelling_belief__(material, baseline_predictions[i])
                y_pred.append(y_sample)
                final_decisions.append(final_decision)
        if show_decision:
            return y_pred, final_decisions
        else:
            return y_pred
    
    def predict(self, X, trace=False, spark=False, show_decision=False, baseline_predictions=None):
        return self.__predict__(X, trace, spark, show_decision, baseline_predictions)

    def predict_proba(self, X, trace=False, spark=False, show_decision=False, baseline_predictions=None):
        # Predict probabilities for each class
        y_pred, final_decisions = self.__predict__(X, trace=trace, spark=spark, show_decision=True, baseline_predictions=baseline_predictions)
        probs = []
        for final_decision in final_decisions:
            m_High = final_decision[frozenset({"High"})]
            m_Low = final_decision[frozenset({"Low"})]
            m_Unk = final_decision[frozenset({"High", "Low"})]
            probs.append(
                [m_High + m_Unk/2, m_Low + m_Unk/2]
            )
        return np.array(probs)

class ExpertParser(object):

    def __init__(self, name, expert_data, seperate_symbol="|", expert_model="LLM"):
        self.name = name
        self.expert_data = expert_data
        self.seperate_symbol = seperate_symbol
        self.expert_model = expert_model

    def __init_similarity_matrices__(self, subsets):
        """
        Return data frames containing data frames contain similarity, dissimilarity and uncertainty between considered subsets.
        """
        n_subsets = len(subsets)
        columns_name = [self.seperate_symbol.join(sorted(k)) for k in subsets]

        similarity_matrix = np.zeros((n_subsets,n_subsets))
        np.fill_diagonal(similarity_matrix, 1)
        df_similarity = pd.DataFrame(similarity_matrix, columns=columns_name, index=columns_name)

        dissimilarity_matrix = np.zeros((n_subsets,n_subsets))
        df_dissimilarity = pd.DataFrame(dissimilarity_matrix, columns=columns_name, index=columns_name)

        unknown_matrix = np.ones((n_subsets,n_subsets))
        np.fill_diagonal(unknown_matrix, 0)
        df_uncertainty = pd.DataFrame(unknown_matrix, columns=columns_name, index=columns_name)

        self.df_similarity = df_similarity
        self.df_dissimilarity = df_dissimilarity
        self.df_uncertainty = df_uncertainty

    def __update_similarity_matrices__(
        self, index_t, index_v, 
        similar_score, dissimilar_score, unk_score
    ):
        self.df_similarity.loc[index_t, index_v] = similar_score
        self.df_dissimilarity.loc[index_t, index_v] = dissimilar_score
        self.df_uncertainty.loc[index_t, index_v] = unk_score
        self.df_similarity.loc[index_v, index_t] = similar_score
        self.df_dissimilarity.loc[index_v, index_t] = dissimilar_score
        self.df_uncertainty.loc[index_v, index_t] = unk_score 

    def __parse_data__(self, discounting_factor=1):
        for data in self.expert_data:
            e1, e2 = data[0], data[1]
            if self.expert_model == "LLM":
                if data[3] == "Q1Yes":
                    if data[4] == "Q2High":
                        self.__update_similarity_matrices__(
                            e1, e2, discounting_factor, 0, 1 - discounting_factor
                        )
                    elif data[4] == "Q2Medium":
                        self.__update_similarity_matrices__(
                            e1, e2, discounting_factor/2, discounting_factor/2, 1 - discounting_factor
                        )
                    elif data[4] == "Q2Low":
                        self.__update_similarity_matrices__(
                            e1, e2, 0, discounting_factor, 1 - discounting_factor
                        )
                elif data[3] == "Q1No":
                    self.__update_similarity_matrices__(
                        e1, e2, 0, 0, 1
                    )
            else:
                sim, dissim = float(data[2]), float(data[3])
                self.__update_similarity_matrices__(
                    e1, e2, discounting_factor*sim, discounting_factor*dissim, 1 - discounting_factor*(sim + dissim)
                )

    def generate_similarity_matrices(self, subsets, discounting_factor=1):

        # Init similarity matrices
        self.__init_similarity_matrices__(subsets)

        # Parse data to similarity matrices
        self.__parse_data__(discounting_factor)

class ExpertClassifier(EvidentialClassifier):

    def __init__(self, core_set, frame_of_discernment, expert_parser, seperate_symbol="|", n_gram_evidence=2, alpha=0.1, version="v1", df_mask_matrix=None):
        """
        Creates a new classifier.

        It is an object to classify new instance based on the observed data set.
        seperate_symbol: symbol is used to separate elements in the instances of the data set.
        n_gram_evidence: max length of the combinations of element which are used to generate the new instance from observed instances based on substitution method.
        alpha (or alpha): a hyperparameter is used to handle the conflict between pieces of evidence.
        """
        super().__init__(core_set, frame_of_discernment, seperate_symbol, n_gram_evidence, alpha, version, df_mask_matrix)
        self.expert_parser = expert_parser

    def fit(self, X, y, spark=False, weights=None):
        # Init base objects
        similarity_information, mask_matrix = self.__base_fit__(X, y, spark, weights)
            
        # Parse expert data to similarity between materials
        similarity_information.subsets = similarity_information.__generate_subsets__()
        similarity_information.__generate_similarity_matrices__()
        self.expert_parser.generate_similarity_matrices(similarity_information.subsets, discounting_factor=self.alpha)
        similarity_information.df_similarity = self.expert_parser.df_similarity.copy()
        similarity_information.df_dissimilarity = self.expert_parser.df_dissimilarity.copy()
        similarity_information.df_uncertainty = self.expert_parser.df_uncertainty.copy()
        self.similarity_information = similarity_information

class HybridClassifier(object):

    def __init__(self, core_set, frame_of_discernment, expert_parsers, seperate_symbol="|", n_gram_evidence=2, alpha=0.1, version="v1", df_mask_matrix=None, scoring={'f1_macro': 'f1_macro'}):
        """
        Creates a new classifier.

        It is an object to classify new instance based on the observed data set.
        seperate_symbol: symbol is used to separate elements in the instances of the data set.
        n_gram_evidence: max length of the combinations of element which are used to generate the new instance from observed instances based on substitution method.
        alpha (or alpha): a hyperparameter is used to handle the conflict between pieces of evidence.
        """
        self.expert_parsers = expert_parsers
        classifiers = {}

        classifiers["ers"] = EvidentialClassifier(
            core_set, frame_of_discernment, seperate_symbol, 
            n_gram_evidence, alpha, version, 
            df_mask_matrix, discounting_factor=2/3#1/(len(expert_parsers)+1)
        )
        
        for parser in expert_parsers:
            classifiers[parser.name] = ExpertClassifier(
                core_set, frame_of_discernment, parser,
                seperate_symbol, n_gram_evidence, 1/(3*len(expert_parsers)),#1/(len(expert_parsers)+1), 
                version, df_mask_matrix
            )
        self.expert_classifiers = classifiers

        self.n_gram_evidence = n_gram_evidence
        self.core_set = core_set
        self.seperate_symbol = seperate_symbol
        self.subsets = self.__generate_subsets__()
        self.scoring = scoring

    def __generate_subsets__(self):
        """
        Return list of subsets (elements or combinations of elements) is considered about their similarity with each other.
        """
        subsets = []
        for size_subset in range(self.n_gram_evidence + 1):
            for subset in itertools.combinations_with_replacement(self.core_set, size_subset):
                subsets.append(subset)
        return subsets

    def __search_alpha__(self, classifier, X, y, spark=False):
        best_alpha = classifier.alpha
        best_score = 0
        best_classifier = classifier

        if len(X) > 10:
            cv_results = cross_validate(
                classifier, X, y, 
                cv=KFold(n_splits=10, shuffle=True, random_state=0), params={"spark": spark}, scoring=self.scoring
            )
            best_score = 1
            for (k, v) in self.scoring.items():
                best_score *= np.mean(cv_results[f"test_{k}"])
            best_score = np.power(best_score, 1/(len(self.scoring)))
    
            classifier.fit(X, y, spark)
            best_classifier = deepcopy(classifier)
        else:
            cv_results = cross_validate(
                classifier, X, y, 
                cv=LeaveOneOut(), params={"spark": spark}, scoring="accuracy"
            )
            best_score = np.mean(cv_results[f"test_score"])
            classifier.fit(X, y, spark)
            best_classifier = deepcopy(classifier)
        
        return best_classifier, best_alpha, best_score
        # best_alpha = classifier.alpha
        # best_score = 0
        # classifier.fit(X, y, spark)
        # best_classifier = deepcopy(classifier)
        
        # return best_classifier, best_alpha, best_score

    def __combine_multiple_experts__(self, hybrid_classifier, experts):
        similar_set = frozenset({"similar"})
        dissimilar_set = frozenset({"dissimilar"})
        unknown_set = frozenset({"similar", "dissimilar"})
        columns_name = [self.seperate_symbol.join(sorted(k)) for k in self.subsets]
        for e1, e2 in itertools.combinations(columns_name, 2):
            expert_combined_mass_function = MassFunction(
                source=[
                    ({"similar"}, 0), 
                    ({"dissimilar"}, 0), 
                    ({"similar", "dissimilar"}, 1)
                ], coreset={"similar", "dissimilar"}
            )
            for expert in experts:
                alpha = self.summary_classifiers[expert]["score"] # if expert != "ers" else self.summary_classifiers[expert]["score"]#*1/(len(self.expert_parsers)+1)
                # alpha = 0 if alpha < 0.7 else alpha
                sim = self.expert_classifiers[expert].similarity_information.df_similarity.loc[e1,e2]
                dissim = self.expert_classifiers[expert].similarity_information.df_dissimilarity.loc[e1,e2]
                expert_combined_mass_function = expert_combined_mass_function.combine(MassFunction(
                    source=[
                        ({"similar"}, np.float64(sim*alpha)), 
                        ({"dissimilar"}, np.float64(dissim*alpha)), 
                        ({"similar", "dissimilar"}, np.float64(1 - (sim + dissim)*alpha))
                    ], coreset={"similar", "dissimilar"}
                ))
    
            # Update similarity information
            hybrid_classifier.similarity_information.df_similarity.loc[e1, e2] = expert_combined_mass_function[similar_set]
            hybrid_classifier.similarity_information.df_dissimilarity.loc[e1, e2] = expert_combined_mass_function[dissimilar_set]
            hybrid_classifier.similarity_information.df_uncertainty.loc[e1, e2] = expert_combined_mass_function[unknown_set]
            hybrid_classifier.similarity_information.df_similarity.loc[e2, e1] = expert_combined_mass_function[similar_set]
            hybrid_classifier.similarity_information.df_dissimilarity.loc[e2, e1] = expert_combined_mass_function[dissimilar_set]
            hybrid_classifier.similarity_information.df_uncertainty.loc[e2, e1] = expert_combined_mass_function[unknown_set]
        return hybrid_classifier
        
    def fit(self, X, y, spark=False, weights=None):
        self.summary_classifiers = {}
        for key, classifier in self.expert_classifiers.items():
            best_model, alpha, best_score = self.__search_alpha__(classifier, X, y, spark)
            self.summary_classifiers[key] = {
                "alpha": alpha,
                "score": best_score
            }
            self.expert_classifiers[key] = best_model     

    def predict(
        self, X, experts=None, 
        trace=False, spark=False, show_decision=False,
        baseline_predictions=None
    ):
        # Init hybrid classifier
        hybrid_classifier = deepcopy(self.expert_classifiers["ers"])

        # Combine classifiers
        if experts is None:
            experts = self.expert_classifiers.keys()
        hybrid_classifier = self.__combine_multiple_experts__(hybrid_classifier, experts)

        return hybrid_classifier.predict(X, trace, spark, show_decision, baseline_predictions)
        
            
            